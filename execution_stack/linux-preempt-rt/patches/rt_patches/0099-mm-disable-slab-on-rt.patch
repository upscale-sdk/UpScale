From 70cb58ca243509855e4269436d4b491e339708cb Mon Sep 17 00:00:00 2001
From: Thomas Gleixner <tglx@linutronix.de>
Date: Mon, 12 Aug 2013 09:16:09 +0200
Subject: [PATCH 099/311] mm: disable slab on rt

---
 init/Kconfig | 1 +
 mm/slab.h    | 2 +-
 2 files changed, 2 insertions(+), 1 deletion(-)

diff --git a/init/Kconfig b/init/Kconfig
index 78f7f01..67af9a0 100644
--- a/init/Kconfig
+++ b/init/Kconfig
@@ -1534,6 +1534,7 @@ choice
 
 config SLAB
 	bool "SLAB"
+	depends on !PREEMPT_RT_FULL
 	help
 	  The regular slab allocator that is established and known to work
 	  well in all environments. It organizes cache hot objects in
diff --git a/mm/slab.h b/mm/slab.h
index f96b49e..c4db26f 100644
--- a/mm/slab.h
+++ b/mm/slab.h
@@ -245,7 +245,7 @@ static inline struct kmem_cache *cache_from_obj(struct kmem_cache *s, void *x)
  * The slab lists for all objects.
  */
 struct kmem_cache_node {
-	spinlock_t list_lock;
+	raw_spinlock_t list_lock;
 
 #ifdef CONFIG_SLAB
 	struct list_head slabs_partial;	/* partial list first, better asm code */
-- 
1.8.3.1

